\documentclass{llncs}
\usepackage{mathpartir}
\usepackage{bigpage}
\usepackage{bcprules}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{stmaryrd}

\newcommand{\new}{\mathsf{new}}
\newcommand{\interp}[1]{\llbracket #1 \rrbracket}
\newcommand{\maps}{\colon}
\newcommand{\Th}{\mathrm{Th}}
\newcommand{\Gph}{\mathrm{Gph}}
\newcommand{\FinSet}{\mathrm{FinSet}}
\newcommand{\FPGphCat}{\mathrm{FPGphCat}}
\newcommand{\Set}{\mathrm{Set}}
\newcommand{\Cat}{\mathrm{Cat}}
\newcommand{\Calc}{\mathrm{Calc}}
\newcommand{\Mon}{\mathrm{Mon}}
\newcommand{\BoolAlg}{\mathrm{BoolAlg}}
\renewcommand{\Form}{\mathrm{Form}}
\newcommand{\leftu}{\mathrm{left}}
\newcommand{\rightu}{\mathrm{right}}
\newcommand{\send}{\mathrm{send}}
\newcommand{\recv}{\mathrm{recv}}
\newcommand{\comm}{\mathrm{comm}}
\renewcommand{\quote}[1]{``#1"}
\newcommand{\deref}[1]{\mathrm{eval}(#1)}
\newcommand{\op}{\mathrm{op}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\pic}{$\pi$-calculus}

% Double brackets
\newcommand{\ldb}{[\![}
\newcommand{\rdb}{]\!]}
\newcommand{\ldrb}{(\!(}
\newcommand{\rdrb}{)\!)}
\newcommand{\lrbb}{(\!|}
\newcommand{\rrbb}{|\!)}
\newcommand{\lliftb}{\langle\!|}
\newcommand{\rliftb}{|\!\rangle}
%\newcommand{\plogp}{:\!-}
\newcommand{\plogp}{\leftarrow}
%\newcommand{\plogp}{\coloneq}
% \newcommand{\lpquote}{\langle}
% \newcommand{\rpquote}{\rangle}
% \newcommand{\lpquote}{\lceil}
% \newcommand{\rpquote}{\rceil}
\newcommand{\lpquote}{\ulcorner}
\newcommand{\rpquote}{\urcorner}
\newcommand{\wbbisim}{\stackrel{\centerdot}{\approx}} %weak barbed bisimilar

% SYNTAX
\newcommand{\id}[1]{\texttt{#1}}
\newcommand{\none}{\emptyset}
\newcommand{\eps}{\epsilon}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\rep}[2]{\id{\{$#1$,$#2$\}}}
\newcommand{\elt}[2]{\id{$#1$[$#2$]}}
\newcommand{\infinity}{$\infty$}

\newcommand{\pzero}{\mathbin{0}}
\newcommand{\seq}{\mathbin{\id{,}}}
\newcommand{\all}{\mathbin{\id{\&}}}
\newcommand{\choice}{\mathbin{\id{|}}}
\newcommand{\altern}{\mathbin{\id{+}}}
\newcommand{\juxtap}{\mathbin{\id{|}}}
\newcommand{\concat}{\mathbin{.}}
\newcommand{\punify}{\mathbin{\id{:=:}}}
\newcommand{\fuse}{\mathbin{\id{=}}}
\newcommand{\scong}{\mathbin{\equiv}}
\newcommand{\nameeq}{\mathbin{\equiv_N}}
\newcommand{\alphaeq}{\mathbin{\equiv_{\alpha}}}
\newcommand{\names}[1]{\mathbin{\mathcal{N}(#1)}}
\newcommand{\freenames}[1]{\mathbin{\mathsf{FN}(#1)}}
\newcommand{\boundnames}[1]{\mathbin{\mathsf{BN}(#1)}}
%\newcommand{\lift}[2]{\texttt{lift} \; #1 \concat #2}
\newcommand{\binpar}[2]{#1 | #2}
\newcommand{\outputp}[2]{#1!(#2)}
\newcommand{\prefix}[3]{#1?(#2) . #3}
\newcommand{\lift}[2]{#1 \lliftb #2 \rliftb}
\newcommand{\clift}[1]{\lliftb #1 \rliftb}
\newcommand{\quotep}[1]{\mathsf{@}#1}
\newcommand{\dropn}[1]{\mathsf{*}#1}
\newcommand{\procn}[1]{\stackrel{\vee}{x}}

\newcommand{\newp}[2]{(\newkw \; #1 ) #2}
\newcommand{\bangp}[1]{! #1}

\newcommand{\substp}[2]{\{ \quotep{#1} / \quotep{#2} \}}
\newcommand{\substn}[2]{\{ #1 / #2 \}}

\newcommand{\psubstp}[2]{\widehat{\substp{#1}{#2}}}
\newcommand{\psubstn}[2]{\widehat{\substn{#1}{#2}}}

\newcommand{\applyp}[2]{#1 \langle #2 \rangle}
\newcommand{\absp}[2]{( #1 ) #2}
\newcommand{\annihilate}[1]{#1^{\times}}
\newcommand{\dualize}[1]{#1^{\bullet}}

\newcommand{\transitions}[3]{\mathbin{#1 \stackrel{#2}{\longrightarrow} #3}}
\newcommand{\meaningof}[1]{\ldb #1 \rdb}
\newcommand{\pmeaningof}[1]{\ldb #1 \rdb}
\newcommand{\nmeaningof}[1]{\lrbb #1 \rrbb}

\newcommand{\Proc}{\mathbin{Proc}}
\newcommand{\QProc}{\quotep{\mathbin{Proc}}}

\newcommand{\bc}{\mathbin{\mathbf{::=}}}
\newcommand{\bm}{\mathbin{\mathbf\mid}}

\newcommand{\rel}[1]{\;{\mathcal #1}\;} %relation
\newcommand{\red}{\rightarrow}
\newcommand{\wred}{\Rightarrow}
\newcommand{\redhat}{\hat{\longrightarrow}}
\newcommand{\lred}[1]{\stackrel{#1}{\longrightarrow}} %transitions
\newcommand{\wlred}[1]{\stackrel{#1}{\Longrightarrow}}
\newcommand{\vect}[1]{\stackrel{\rightharpoonup}{#1}}

\newcommand{\rhoc}{$\rho$-calculus}

\makeatletter
\gdef\tshortstack{\@ifnextchar[\@tshortstack{\@tshortstack[c]}}
\gdef\@tshortstack[#1]{%
  \leavevmode
  \vtop\bgroup
    \baselineskip-\p@\lineskip 3\p@
    \let\mb@l\hss\let\mb@r\hss
    \expandafter\let\csname mb@#1\endcsname\relax
    \let\\\@stackcr
    \@ishortstack}
\makeatother

\title{Name-free combinators for concurrency}
\author{
L.G. Meredith\inst{1}\\
\and
Michael Stay\inst{2}\\
}
\institute{
  {RChain Cooperative}\\
  \email{\fontsize{8}{8}\selectfont greg@rchain.coop}
  \and
  {Pyrofex Corp.}\\
  \email{\fontsize{8}{8}\selectfont stay@pyrofex.net}\\
}
\begin{document}
\maketitle
\begin{abstract}
\noindent
  Yoshida demonstrated how to eliminate the bound names coming from
  the input prefix in the asynchronous {\pic}, but her combinators
  still depend on the $\new$ operator to bind names.
  We modify Yoshida's combinators by replacing $\new$ and replication
  with reflective operators to provide the first combinator calculus
  with no bound names into which the asynchronous {\pic} has a faithful
  embedding.  We also show that multisorted Lawvere theories enriched 
  over graphs suffice to capture the operational semantics of the calculus.
\end{abstract}

\section{Introduction}

Many term calculi, like $\lambda$-calculus or {\pic}, involve binders
for names, and the mathematics of bound variable names is
subtle. Sch\"onfinkel introduced the SKI combinator calculus in 1924
to clarify the role of quantified variables in intuitionistic logic by
eliminating them \cite{finkel}; Curry developed Sch\"onfinkel's ideas
much further. The difficulties are not merely theoretical, but
represent a real practical challenge in the design of programming
languages. In fact binding is one of the key features of
the PoPLMark Challenge \cite{PoPLMark}. Certainly, the recent work by Jamie
Gabbay and Andrew Pitts \cite{DBLP:journals/fac/GabbayP02} and others
\cite{DBLP:journals/jcss/Clouston14} on nominal set theory has put the
study of bound names and substitution on a much nicer foundation that
can be shown to extend to practical implementations. However, it
introduces an intriguing conundrum.

Specifically, the work of Gabbay and Pitts relies on a version of set
theory that admits an infinite supply of ``atoms''. This raises the
question of where these atoms come from, which has both theoretical and
practical implications. On the practical side, infinite sets of
``atomic'' entities, i.e. entities with no internal structure, are not
realizable on modern computers. Modern computers fundamentally rely on
sets of elements with effective internal structure to provide the kind
of compression necessary to produce or compute with infinite sets. The
natural numbers is a prime example. Because of their very regular
internal structure the entire set can be represented by a single
recursive equation. Potentially then, the natural numbers or some
other effectively representable set could provide the source of atoms
used in an FM-set theoretic account of binding in practical
implementations. However, this raises a new question.

In order to represent and compute these effectively representable sets
a notion of computation must already be in place. If that notion of
computation relies on a notion of binding, then not a lot progress has
been made! As in \cite{DBLP:journals/entcs/MeredithR05} we argue that
this circularity, instead of being an obstacle to overcome, might be a
clue to an alternative approach to binding phenomena; and one that
ties together two important computational phenomena that have not
normally been considered as related. More explicitly, we extend the
argument made by Meredith and Radestock that reflection suffices to
provide the ``atoms'' used in the {\pic} as channels to produce the
first name-free set of combinators that enjoys a full and faithful
interpretation of the calculus.

While the focus of the paper is largely on the technical results it is
useful to consider the larger context motivating them. Reflection and
meta-programming features more generally are part of a growing number
of mainstream languages. Java, C\#, even the Haskell and OCaml
communities have seen growing interest in these features with efforts
like template Haskell and MetaOCaml, respectively. In large measure
this has to do the fact that programming at industrial scale requires
the leverage of computer programs to write computer programs. Thus,
meta-programming features are simply a practical necessity. On the
other hand, reflection and meta-programming have not received a
theoretical account that fits well with strong typing. This is one of
the reasons why language designs based on typed $\lambda$-calculi have
been so slow to adopt reflection as a feature by comparison to other
language designs.

In this setting, the idea that a single feature already enjoying
widespread adoption could account for such a subtle phenomenon as the
kind of binding found in the {\pic} is both intriguing and worth
exploring, even if FM set theory provides a satisfying account of
computation with nominal phenomena in other respects. However, it is
precisely the foundational theoretical questions raised by the FM set
theoretic approach that motivates the investigation in the first place:
what better place to look for the source of ``atoms'' than in the
reification of theory of computation requiring them? 

To be clear, we are not focusing on ordinary abstraction, as that is
well solved by abstraction elimination from the $\lambda$-calculus to
$\mathcal{SKI}$. Instead we are focused on binders for fresh
names. For example, the {\pic} (\cite{milner91polyadicpi}) has two
binders for names: the $\new$ operator, which introduces a new name
into scope, and the input prefix, which introduces a name for labeling
locations for substitution.  Yoshida
\cite{DBLP:journals/tcs/Yoshida02} describes an elimination algorithm
that gets rid of input prefixes which corresponds in many respects to
the elimination of lambda abstraction; but her combinators still
fundamentally depend on the $\new$ operator.  In complementary work,
Meredith and Radestock \cite{DBLP:journals/entcs/MeredithR05}
introduce reflective operators into a higher-order {\pic} and implment
$\new$ and replication in terms of reflection.  Here, we present a
fusion of those ideas: a name-free concurrent combinator calculus into
which Yoshida's combinators have a faithful embedding.

\subsubsection{Outline of the paper}
To be fully self-contained this paper would need to present four
different calculi: the original {\pic}, Yoshida's combinator calculus,
and the encoding from the term calculus to the combinator; the
{\rhoc}, and the encoding from the {\pic} to the {\rhoc} and the new
reflective combinator calculus, and the encoding from the term
calculus to the reflective combinator calculus. This would provide all
the technical machinery to illustrate how the two encoding techniques,
prefix elimination and $\new$ elimination, combine and how the
encoding from the {\pic} can be constructed by composing the
encoding into the {\rhoc} with the encoding into the reflective
combinator calculus.

\section{A reflective higher-order concurrent combinator calculus}

\subsection{Yoshida's original combinator calculus}

\begin{mathpar}
  \inferrule* [lab=atom] {} { P \bc 0 \;|\; m(a,b) \;|\; d(a,b,c) \;|\; k(a) \;|\; fw(a,b) \;|\; br(a,b) \;|\; bl(a,b) \;|\; s(a,b,c) }
  \and
  \inferrule* [lab=process] {} {\bm \; (\new\; a)P \;|\; P|P \;|\; !P}
\end{mathpar}

As in the {\pic}, the $\new$ operator is a binding operator
for names, so Yoshida's calculus also has a notion of free and bound names.

\begin{mathpar}
  \freenames{\pzero} := \emptyset
  \and
  \freenames{k(a)} := \{ a \}
  \and
  \freenames{m(a,b)} = \freenames{f(a,b)} = \freenames{br(a,b)} = \freenames{bl(a,b)} := \{ a, b \}
  \and
  \freenames{d(a,b,c)} = \freenames{s(a,b,c)} := \{ a, b, c \}
  \and
  \freenames{(\new\;a)P} := \freenames{P} \setminus \{ a \}
  \and
  \freenames{P|Q} := \freenames{P} \cup \freenames{Q}
  \and
  \freenames{!P} := \freenames{P}
\end{mathpar}

The bound names of a process, $\boundnames{P}$, are those names occurring in $P$
that are not free. For example, in $(\new\; b)m(a,b)$, the name $a$ is free, while $b$ is bound.

In the following definition, $\vect{x}$ indicates a list of names,
$u:\vect{x}$ indicates the concatenation of $u$ onto the vector, and
abuse set notation $u \in \vect{x}$ to assert or require that $u$
occurs in $\vect{x}$.

\begin{definition}
Two processes, $P,Q$, are alpha-equivalent if $P = Q\{\vect{y}/\vect{x}\}$ for
some $\vect{x} \in \boundnames{Q},\vect{y} \in \boundnames{P}$, where $Q\{\vect{y}/\vect{x}\}$
denotes the capture-avoiding substitution of $\vect{y}$ for $\vect{x}$ in $Q$.
\end{definition}

\begin{definition}
  The {\em structural congruence} $\equiv$
  between processes \cite{SangiorgiWalker} is the least congruence containing
  alpha-equivalence and satisfying the commutative monoid laws
  (associativity, commutativity and $\pzero$ as identity) for parallel
  composition $|$.
\end{definition}

Rewrite rules
\[\begin{array}{rl}
  d(a,b,c) | m(a,x) & \red m(b,x) | m(c,x) \\
  k(a) | m(a,x) & \red 0 \\
  fw(a,b) | m(a,x) & \red m(b,x) \\
\end{array} \quad \quad
\begin{array}{rl}
  br(a,b) | m(a,x) & \red fw(b,x) \\
  bl(a,b) | m(a,x) & \red fw(x,b) \\
  s(a,b,c) | m(a,x) & \red fw(b,c)
\end{array}\]
\[\begin{array}{rl}
  !P & \red P|!P \\
\end{array}\]
\begin{mathpar}
  \inferrule* {{P} \red {P}'} {{{P} | {Q}} \red {{P}' | {Q}}}
  \and
  \inferrule* {{{P} \scong {P}'} \andalso {{P}' \red {Q}'} \andalso {{Q}' \scong {Q}}}{{P} \red {Q}}
\end{mathpar}

\subsection{Reflective higher-order (RHO) combinator calculus}
The {\pic} is not a closed theory, but rather a theory dependent upon
some theory of names. Taking an operational view, one may think of the
{\pic} as a procedure that when handed a theory of names provides a
theory of processes that communicate over those names. This openness
of the theory has been exploited in {\pic} implementations like the
execution engine in Microsoft's Biztalk \cite{biztalk}, where an
ancillary binding language provides a means of specifying a `theory'
of names: {\em e.g.}, names may be TCP/IP ports, or URLs, or object
references, {\em etc.}  But foundationally, one might ask if there is
a closed theory of processes, {\em i.e.} one in which the theory of
names arises from and is wholly determined by the theory of
processes. Meredith and Radestock have shown that this is not only
possible, but results in a calculus that enjoys both the features of
concurrency and meta-programming
\cite{DBLP:journals/entcs/MeredithR05}. The key idea is to provide the
ability to quote processes, effectively reifying them as names, and to
unquote them, effectively reflecting names back as processes.

The same technique can be applied to Yoshida's combinators. We remove
new names and replication, introduce quoting/unquoting operators,
allow processes in the second argument of a send, and introduce an
extra rewrite governing the interaction between sending and unquoting.

\begin{mathpar}
  \inferrule* [lab=atom] {} { P \bc 0 \;|\; m(a,P) \;|\; d(a,b,c) \;|\; k(a) \;|\; fw(a,b) \;|\; br(a,b) \;|\; bl(a,b) \;|\; s(a,b,c) }
  \and
  \inferrule* [lab=process] {} {\bm \; *a \;|\; P|P}
  \and
  \inferrule* [lab=nominal] {} {a \bc \quotep{P}}
\end{mathpar}

Rewrite rules
\[\begin{array}{rl}
  d(a,b,c) | m(a,P) & \red m(b,P) | m(c,P) \\
  k(a) | m(a,P) & \red 0 \\
  fw(a,b) | m(a,P) & \red m(b,P) \\
  br(a,b) | m(a,P) & \red fw(b,@(P)) \\  
\end{array} \quad \quad
\begin{array}{rl}
  bl(a,b) | m(a,P) & \red fw(@(P),b) \\
  s(a,b,c) | m(a,P) & \red fw(b,c) \\
  *(a) | m(a,P) & \red P
\end{array}\]
\begin{mathpar}
  \inferrule* {{P} \red {P}'} {{{P} | {Q}} \red {{P}' | {Q}}}
  \and
  \inferrule* {{{P} \scong {P}'} \andalso {{P}' \red {Q}'} \andalso {{Q}' \scong {Q}}}{{P} \red {Q}}
\end{mathpar}

\begin{definition}
  The {\em structural congruence} $\equiv$
  between processes \cite{SangiorgiWalker} is the least congruence
  satisfying the commutative monoid laws
  (associativity, commutativity and $\pzero$ as identity) for parallel
  composition $|$ and $*(@(P)) \equiv P$.
\end{definition}

Note that alpha equivalence is no longer part of structural congruence.  While there is a faithful embedding of Yoshida's combinators into RHO combinators (see below), RHO combinators can see the internal structure of names and distinguish them.

\subsubsection{Implementing replication with reflection}

% D_x = x?(y).(x<*y> | *y)
% 
%       x#y.(x<*y> | *y)
% 1 => vc1c2.(d(xc1c2) | c1#y.m(x*y) | c2#y.*y)
% 7 => vc1c2.(d(xc1c2) | fw(c1x) | c2#y.*y)
% * => vc1c2.(d(xc1c2) | fw(c1x) | *c2)
% 
% 
% 
% vc1c2.(d(xc1c2) | fw(c1x) | *c2) | m(xP)
% => vc1c2.(d(xc1c2) | fw(c1x) | *c2 | m(xP))
% => vc1c2.(d(xc1c2) | m(xP) | fw(c1x) | *c2)
% => vc1c2.(m(c1P) | m(c2P) | fw(c1x) | *c2)
% => vc1c2.(m(xP) | m(c2P) | *c2)
% => vc1c2.(m(xP) | P)
% 
% !_x P = m(x(D_x | P)) | D_x
% = vc1c2.(d(xc1c2) | fw(c1x) | *c2 | m(x(D_x | P)))
% = vc1c2.(m(c1(D_x | P)) | m(c2(D_x | P)) | fw(c1x) | *c2 | m(x(D_x | P)))
% = vc1c2.(m(x(D_x | P)) | m(c2(D_x | P)) | *c2)
% = vc1c2.(m(x(D_x | P)) | D_x | P)
% = m(x(D_x | P)) | D_x | P
As mentioned before, it is known that replication (and hence
recursion) can be implemented in a higher-order process algebra
\cite{SangiorgiWalker}. As our first example of calculation with the
machinery thus far presented we give the construction explicitly in
the RHO combinator calculus.

\begin{definition}[Replication]
  \label{replication}
  $D(x,v,w) := (d(x,v,w) | fw(v,x) | {*}(w))$
\end{definition}
\[\begin{array}{rl}
  !_{(x,v,w)} P &= m(x,D(x,v,w) \; |\; P) \; |\; D(x,v,w) \\
        &= d(x,v,w) \; |\; fw(v,x) \; |\; {*}(w) \; |\; m(x,D(x,v,w) \; |\; P) \\
        &\red m(v,D(x,v,w) \; |\; P) \; |\; m(w,D(x,v,w) \; |\; P) \; |\; fw(v,x) \; |\; {*}(w) \; |\; m(x,D(x,v,w) \; |\; P) \\
        &\red m(x,D(x,v,w) \; |\; P) \; |\; m(w,D(x,v,w) \; |\; P) \; |\; {*}(w) \\
        &\red m(x,D(x,v,w) \; |\; P) \; |\; D(x,v,w) \; |\; P \\
        & = \; !_{(x,v,w)} P \; |\; P
\end{array}\]

Of course, this encoding, as an implementation, runs away, unfolding
$\bangp{P}$ eagerly. It is possible to obtain a lazier
replication operator restricted to the embedding of
input-guarded $\pi$ processes. The reader familiar with the
$\lambda$-calculus will have noticed the similarity between $D$ and
the ``paradoxical'' or ``fixed point'' combinator $Y$.

\subsubsection{Implementing new names with reflection}

Here we provide an encoding of Yoshida's combinator calculus into the
RHO combinator calculus. Since all names are global in the RHO
combinator calculus, we encounter a small complication in the
treatment of free names at the outset. There are several ways to
handle this.  One is to insist that the translation be handed a closed
program, one in which all names are bound either by input or by
restriction, but this feels inelegant. Another is to provide
an environment, $r : \mathcal{N}_{\mbox{\tiny Yoshida}} \rightarrow \QProc$, for
mapping the free names in a Yoshida process into names in the RHO
combinator calculus. Maintaining the updates to the environment,
however, obscures the simplicity of the translation. We adopt a third
alternative.

To hammer home the point that Yoshida's combinator calculus is
parameterized in a theory of names, we instantiate her calculus with
the names of the RHO combinator calculus. This is no different than
instantiating her calculus using the natural numbers, or the set of URLs as the
set of names. Just as there is no connection between the structure of
these kinds of names and the structure of processes in the {\pic},
there is no connection between the processes quoted in the names used
by the theory and the processes generated by the theory, and we
exploit this fact.

Let $\QProc$ be set of names in the RHO combinator calculus, $\Proc$
be the set of terms of the RHO combinator calculus, and
$\Proc_{\mbox{\tiny Yoshida}}$ be the set of terms of her combinator
calculus built using $\QProc$ \emph{as the names}. The translation will be
given in terms of a function \[\meaningof{-}_2( -, - ) : 
    \Proc_{\mbox{\tiny Yoshida}} \times \QProc {\times} \QProc \red \Proc.\] 
The guiding intuition is that we construct alongside the process a distributed memory
allocator, the process' access to which is mediated through the second argument
to the function, called $p$ below. The first argument, called $n$ below, determines the shape of the memory for the given allocator.

Since Yoshida's calculus is parametric in a set of names, we can
choose $\QProc$ for that set.  Given a process $P$ in Yoshida's
calculus, we pick names $n$ and $p$ in the RHO calculus such that $n \neq p$
and both are distinct from the free names of $P$.  Then we define

\begin{equation*}
  \meaningof{P} = \meaningof{P}_2(n, p),
\end{equation*}

Name allocation will make heavy use of the following two name
constructors

\begin{eqnarray*}
  x^l & := & \quotep{b_{l}(x,m(x,*x))} \\
  x^r & := & \quotep{b_{r}(x,m(x,*x))}
\end{eqnarray*}

Note that by construction, $\quotep{P}$ cannot occur as a name in $P$
and hence any name derived from a process that is built using
$\quotep{P}$ cannot occur in $P$. Thus, the effect of the superscripts
$l$ and $r$ on a name $x$ is to construct a name that is guaranteed to
be fresh with respect to the free names of the process being
interpreted. More generally, mentioning a name, say $n$, in the
constructor of a another name, say $n'$, guarantees distinction
between $n$ and $n'$; likewise, mentioning a process, say $P$, in the
constructor of a name $n$ guarantees that $n$ is fresh in $P$. The
particular choices of combinators used in the name
constructors are irrelevant for the purposes of freshness. We
make heavy use of this fact in our interpretation of prefix
elimination.

The interpretation function $\meaningof{-}_2(n, p)$ is straightforward
for all but replication and $\mathsf{new}$.

\begin{eqnarray*}
    \meaningof{\pzero}_2 (n,p)
      & = &
       \pzero \\
    \meaningof{\emph{c}(\vect{a})}_2 (n,p) 
      & = & 
      \emph{c}(\vect{a})\mbox{, where $\emph{c}$ is any combinator but $m$} \\
    \meaningof{m(aP)}_2 (n,p) 
      & = & 
          m(a \meaningof{P}_2 (n,p)) \\
    \meaningof{P \juxtap Q}_2 (n,p) 
      & = & 
    \meaningof{P}_2 (n^l, p^l)
         \juxtap \meaningof{Q}_2 (n^r, p^r) \\ 
\end{eqnarray*}

These latter two forms require extra care. We define them in terms of
a prefix form and then use a version of Yoshida's prefix elimination
to remove the prefix.

\begin{eqnarray*}
    \meaningof{\id{!} P}_2 (n,p)
          & = & \binpar{m(x, \meaningof{P}_3(n^r,p^r))}
                  {\binpar{D(x,v,w)}
                    {\binpar{m(n^r, *n^l)}{m(n^r, *n^l)}}} \\
                  & & \mbox{where } 
                      x = @(\meaningof{P}_2(n,p))^{ll}, 
                      v = @(\meaningof{P}_2(n,p))^{lr}, \mbox{ and }
                      w = @(\meaningof{P}_2(n,p))^{rr} \\
    \meaningof{(\new \; x ) P}_2 (n, p) 
          & = & 
         \meaningof{\prefix{p}{x}{\binpar{\meaningof{P}_2 ( n^l, p^l )}{m(p, *n)}}}_4(n, p)
\end{eqnarray*}

As expected, the interpretation of replication makes use of the $D$
operator defined above. Note that name allocation is intertwined with
prefix and new elimination.
         
\begin{eqnarray*}
  \meaningof{P}_3(n, p) 
    & := & 
      \meaningof{\prefix{n}{n'}{\prefix{p}{p'}{(\binpar{\meaningof{P}_2(n',p')}
        {(\binpar{D(x)}{\binpar{\outputp{n}{n'^l}}{\outputp{p}{p'^l}}})})}}}_4. \\
\end{eqnarray*}

To handle prefix elimination we must import most of Yoshida's
algorithm. The key difference is that we must allocate names that
guarantee freshness relative to the free names of the processes being
translated. In those rules below with a ``where'' clause, the specific
choice of combinators in the names is not so important as mentioning
those names and processes with respect to which the name mush be fresh.
For example, in rule $I$, for prefix to a parallel
composition, we must ensure that $v$ and $w$ are fresh with respect to
the names in $P$ and $Q$, and distinct from each other, and then we
must update both the name allocator for each parallel component and
the channels on which fresh names are communicate (so that there is no
interference between the two components) in the recursive call. 

Because the input to $\meaningof{-}_4$ is already in combinator form,
we do not have to import rules 2 -- 4 of her algorithm. Like her, we
assume the following annotations ($+$ stands for the output and $−$
stands for the input), which denote how each name is used in the rules
of interaction:

\[m(a^{+},v^{\pm});d(a^{−},b^{+},c^{+});k(a^{−});fw(a^{−},b^{+});bl(a^{−}b^{+});br(a^{−}b^{−});s(a^{−}b^{−}c^{+})\]

Note the annotated polarities are preserved by reduction, e.g.
\[\binpar{d(a^{−},b^{+},c^{+})}{m(a^{+},v)} \to \binpar{m(b^{+},v)}{m(b^{+},v)}\]

Similarly, for economy of expression, we emulate Yoshida's use of
$\emph{c}$ to represent any combinator matching the arity
specification. 

\[\begin{array}{llrl}
(I)&  \meaningof{\prefix{p}{x}{\binpar{P}{Q}}}_4(n, q) 
    & := & 
    (d(p,v,w)|\binpar{\meaningof{\prefix{v}{x}{P}}_{4}(n_{1}, q_{1})}{\meaningof{\prefix{w}{x}{Q}}_{4}(n_{2}, q_{2}) } \\
    & & & \mbox{where $v = \quotep{(m(q,\binpar{b_{l}(q,n)}{\binpar{P}{Q}}))}$, $w = \quotep{(m(q,\binpar{b_{r}(q,n)}{\binpar{P}{Q}}))}$,} \\
    & & &\mbox{$n_{1} = \quotep{(\binpar{b_{l}(v,w)}{m(q,m(v,*w))})}$, $n_{2} = \quotep{(\binpar{b_{r}(v,w)}{m(q,m(v,*w))})}$} \\
    & & &\mbox{$q_{1} = \quotep{(\binpar{b_{l}(n_{1},n_{2})}{m(q,m(v,*w))})}$, $q_{2} = \quotep{(\binpar{b_{r}(n_{1},n_{2})}{m(q,m(v,*w))})}$} \\
(V)&  \meaningof{\prefix{p}{x}{\emph{c}(v^{+},w)}}_4(n, q) 
    & := & 
    s(p,a,v)|\emph{c}(a^{+},\vect{w})
    \mbox{, where $a = @(\binpar{m(q,*n)}{\emph{c}(v^{+},\vect{w})})$ and $x \not\in v : \vect{w}$}\\
(VI)&  \meaningof{\prefix{p}{x}{\emph{c}(v^{-},\vect{w})}}_4(n, q) 
    & := & 
    s(p,v,a)|\emph{c}(a^{-},\vect{w})
    \mbox{, where $a = @(m(q,*n)|\emph{c}(v^{-},w))$ and $x \not\in v : \vect{w}$} \\
(VII)&  \meaningof{\prefix{p}{x}{m(v,x)}}_4(n, q) 
    & := & 
    fw(p,v) \\
(VIII)&  \meaningof{\prefix{p}{x}{fw(x,v)}}_4(n, q) 
    & := & 
    b_{l}(p,v) \\
(IX)&  \meaningof{\prefix{p}{x}{fw(v,x)}}_4(n, q) 
    & := & 
    b_{r}(p,v) \\
(X)&  \meaningof{\prefix{p}{x}{\emph{c}(\vect{v},x^{+},\vect{w})}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{\binpar{fw(a,x)}{\emph{c}(\vect{v},a^{+},\vect{w})}}}_4(n', q)\\
    & & & \mbox{where $a = @(\binpar{m(q,*n)}{\emph{c}(\vect{v},x^{+},\vect{w})})$} \mbox{ and $n'= \quotep{(m(a,m(q,*n)))}$} \\
(XI)&  \meaningof{\prefix{p}{x}{\emph{c}(x^{-},\vect{v})}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{\binpar{fw(x,a)}{\emph{c}(a^{-},\vect{v})}}}_4(n', q)\\
    & & & \mbox{where $a = @(\binpar{m(q,*n)}{\emph{c}(x^{-},v)})$} \mbox{ and $n'= \quotep{(m(a,m(q,*n)))}$} \\
(XII)&  \meaningof{\prefix{p}{x}{b_{r}(v,x^{-})}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{(\binpar{d(v,w_{1},w_{2})}{\binpar{s(w_{1},x,w_{3})}{br(w_{2},w_{3})}})}}_{4}(n', q) \\
    & & & \mbox{where $w_{1} = \quotep{(\binpar{b_{l}(q,n)}{m(q,b_{r}(v,x^{-}))})}$, $w_{2} = \quotep{(\binpar{b_{r}(q,n)}{m(q,b_{r}(v,x^{-}))})}$,} \\
    & & & \mbox{$w_{3} = \quotep{(\binpar{b_{l}(p,v)}{m(w_{1},*w_{2}})}$, and $n' = \quotep{(s(w_{1},w_{2},w_{3}))}$} \\
(XIII)&  \meaningof{\prefix{p}{x}{s(v,x^{-},w)}}_4(n, q) 
    & := & 
    \meaningof{\prefix{p}{x}{(\binpar{s(v,w_{1},w_{2})}{\binpar{m(w_{1},*x)}{bl(w_{2},w)}})}}_{4}(n', q) \\
    & & & \mbox{where $w_{1} = @(\binpar{b_{l}(q,n)}{s(v,x^{-},w)})$, $w_{2} = @(\binpar{b_{r}(q,n)}{s(v,x^{-},w)})$,} \\
    & & & \mbox{and $n' = \quotep{(m(w_{1},*w_{2}))}$}
\end{array}\]

Note that all $\new$-binding is now interpreted, as in Wischik's
global $\pi$-calculus, as an input \cite{globalpi}.

It is also noteworthy that the translation is dependent on how the
parallel compositions in a process are associated. Different
associations will result in different bindings for $\new$
names. This will not result in different behavior, however:
while the RHO combinators can encode different behaviors depending
on the choice of name, Yoshida's combinators cannot and the
embedding is insensitive to the choice.

\subsubsection{Faithfulness of the translation}

\begin{definition}
An \emph{observation relation}, $\downarrow_{\mathcal N}$, over a set
of names, $\mathcal N$, is the smallest relation satisfying the rules
below.

\infrule[Out-barb]{y \in {\mathcal N}, \; x \nameeq y}
    {m(x-) \downarrow_{\mathcal N} x}

\infrule[Par-barb]{\mbox{$P\downarrow_{\mathcal N} x$ or $Q\downarrow_{\mathcal N} x$}}
    {\binpar{P}{Q} \downarrow_{\mathcal N} x}

We write $P \Downarrow_{\mathcal N} x$ if there is $Q$ such that 
$P \wred Q$ and $Q \downarrow_{\mathcal N} x$.
\end{definition}

This definition is parametric in the the argument accepted in the
second position in the message combinator, $m(x-)$, {\em i.e.} the payload
of the message: in the RHO combinators the payload is a process,
while in Yoshida's the payload is a name. Likewise, because the
definition of barbed bisimulation given below is dependent on the
definition of the observation relation, the definition is really a
template for the notion of bisimulation that must be instantiated to
the kind of payload accepted by the message combinator.

%% Notice that $\prefix{x}{y}{P}$ has no barb.  Indeed, in {\rhoc} as well
%% as other asynchronous calculi, an observer has no direct means to
%% detect if a message sent has been received or not.

\begin{definition}
%\label{def.bbisim}
An  ${\mathcal N}$-\emph{barbed bisimulation} over a set of names, ${\mathcal N}$, is a symmetric binary relation 
${\mathcal S}_{\mathcal N}$ between agents such that $P\rel{S}_{\mathcal N}Q$ implies:
\begin{enumerate}
\item If $P \red P'$ then $Q \wred Q'$ and $P'\rel{S}_{\mathcal N} Q'$.
\item If $P\downarrow_{\mathcal N} x$, then $Q\Downarrow_{\mathcal N} x$.
\end{enumerate}
$P$ is ${\mathcal N}$-barbed bisimilar to $Q$, written
$P \wbbisim_{\mathcal N} Q$, if $P \rel{S}_{\mathcal N} Q$ for some ${\mathcal N}$-barbed bisimulation ${\mathcal S}_{\mathcal N}$.
\end{definition}

\begin{theorem}
  $P \wbbisim_{\pi} Q \iff \ldb P \rdb \wbbisim_{\texttt{FN}(P)} \ldb Q \rdb$.
\end{theorem}

\begin{proof}[Proof sketch]
  The forward direction $\Rightarrow$ is immediate from the definition
  of the translation. The reverse direction is only interesting in the
  case of $!$ and $\mathsf{new}$. The replication case follows immediately
  from the calculation following definition \ref{replication}. 
  In the $\new$ case, transitions on $\mathsf{new}$-bound
  names will be in one-to-one correspondence with names provided by
  the name parameters of the translation function. By construction,
  these are not observable by the observation relation.
\end{proof}

\begin{remark}
  In light of this theorem, it is worth pointing out that this version
  of the RHO combinators has no rule for \emph{introducing} terms of
  the form $\dropn{x}$. The $br$ and $bl$ combinators introduce new
  names from processes, but the do not introduce new reflection
  terms. Yet, this calculus suffices to faithfully represent the
  Yoshida combinators. This is because the translation function is
  carefully introducing just those terms, via the $D(x,v,w)$ operator,
  guided by the use of replication in the source to the
  translation. 
\end{remark}

\section{Conclusion and future work}
We have shown how to construct a concurrent higher-order combinator
calculus that uses reflection to avoid the necessity for new and bound
names.  Yoshida's combinators, and therefore the asynchronous {\pic},
have a faithful embedding into the calculus.  We have also given a
Gph-theory that captures the calculus' operational semantics.  Just as
the S and K combinators correspond to the axioms of intuitionistic
logic, we anticipate that the combinators of this calculus will be
typable and will correspond to axioms in a logic of concurrency.

\bibliographystyle{amsplain}
\bibliography{rhocomb}

\section{Appendix: The $\pi$-calculus again}
\subsection{\pic}

In this presentation of the {pic} we update the syntax for
input-guarded processes to reflect the widespread adoption of
comprehension notation in languages ranging from Scala to Python for
use in reactive programming. Here we go with the Scala notation
writing $\mathsf{for}( y \leftarrow x )P$ where Milner might have
written $x?(y)P$. Admittedly, it's somewhat more verbose, but conveys
to a younger generation of programmers more familiar with reactive
programming the intended semantics of the expression.

\begin{mathpar}
\inferrule* [lab=process] {} {P, Q \bc \pzero \;\bm\; \mathsf{for}( y
  \leftarrow x )P \;\bm\; x!(y) \;\bm\; (\mathsf{new}\;x)P \;\bm\; P|Q \;\bm\;	\mathsf{*}P}
\end{mathpar}

\subsection{Structural congruence}

\begin{definition}
The {\em structural congruence}, $\equiv$, between processes is 
the least congruence closed with respect to
alpha-renaming, satisfying the abelian monoid laws for 
parallel (associativity, commutativity and $\pzero$ 
as identity), and the following axioms:
\begin{enumerate}
\item the scope laws:
\begin{eqnarray*}
 (\mathsf{new}\;x)\pzero & \equiv & \pzero, \\
 (\mathsf{new}\;x)(\mathsf{new}\;x)P & \equiv & (\mathsf{new}\;x)P, \\
 (\mathsf{new}\;x)(\mathsf{new}\;y)P & \equiv & (\mathsf{new}\;y)(\mathsf{new}\;x)P, \\
 P|(\mathsf{new}\;x)Q & \equiv & (\mathsf{new}\;x)P|Q, \; \mbox{\textit{if} }x \not\in \freenames{P} 
\end{eqnarray*}
\item
the recursion law:
\begin{eqnarray*}
 \mathsf{*}P \equiv P|\mathsf{*}P
\end{eqnarray*}
\item
the name equivalence law:
\begin{eqnarray*}
 P \equiv P \substn{x}{y}, \; \mbox{\textit{if} }x \nameeq y
\end{eqnarray*}
\end{enumerate}
\end{definition}

\subsection{Operational semantics} The operational semantics is standard.

\begin{mathpar}
  \inferrule* [lab=COMM] {} {\mathsf{for}( y \leftarrow x )P | x!(v)
  \red P\substn{\mathsf{v}}{y}}
\end{mathpar}

In addition, we have the following context rules:

\begin{mathpar}
  \inferrule* [lab=PAR]{P \red P'}{P|Q \red P'|Q}
  \and
  \inferrule* [lab=NEW]{P \red P'}{(\mathsf{new}\;x)P \red (\mathsf{new}\;x)P'}
  \and
  \inferrule* [lab=EQUIV]{{P \scong P'} \andalso {P' \red Q'} \andalso {Q' \scong Q}}{P \red Q}
\end{mathpar}


Again, we write $\wred$ for $\red^*$, and rely on context to
distinguish when $\red$ means reduction in the {\pic} and when it
means reduction in the {\rhoc}. The set of {\pic} processes will be
denoted by $\Proc_{\pi}$.

\subsection{The translation}

The translation will be given by a function, $\meaningof{-}( -, - ) :
\Proc_{\pi} \times \QProc \times \QProc \red \Proc$. The guiding
intuition is that we construct alongside the process a distributed memory
allocator, the process' access to which is mediated through the second argument
to the function. The first argument determines the shape of the memory
for the given allocator.

Given a process, $P$, we pick $n$ and $p$ such that $n \neq p$ and
distinct from the free names of $P$. For example, $n = \quotep{\Pi_{m
\in \freenames{P}}\outputp{m}{\quotep{\pzero}}}$ and $p =
\quotep{\Pi_{m \in
\freenames{P}}\prefix{m}{\quotep{\pzero}}{\pzero}}$. Then

\begin{equation*}
	\meaningof{P} = \meaningof{P}_{2nd}( n, p )
\end{equation*}

where

\begin{eqnarray*}
   	\meaningof{\pzero}_{2nd} (  n, p )
   		& = &
   		 \pzero \\
   	\meaningof{x \id{[} y \id{]}}_{2nd} (  n, p ) 
  		& = & 
  		x \id{[} y \id{]} \\
   	\meaningof{x \id{(} y \id{)} \concat P}_{2nd} (  n, p ) 
   		& = & 
 		x \id{(} y \id{)} \concat \meaningof{P}_{2nd} (  n, p ) \\
   	\meaningof{P \juxtap Q}_{2nd} (  n, p ) 
   		& = & 
 		\meaningof{P}_{2nd} ( n^{l}, p^{l} )
   			 \juxtap \meaningof{Q}_{2nd} ( n^{r}, p^{r} ) \\
%    	\meaningof{\id{!} P}_{2nd} (  n, p )
%    		& = & \binpar{\lift{x}{\binpar{upn( n^{lr}, p^{lr}, n^{rl}, p^{rl} )}
% 						      {\meaningof{P}_{3rd}( n^{lr}, p^{lr}, n^{rl}, p^{rl} )}}}
% 		             {\binpar{D(x)}{\binpar{\outputp{n^{lr}}{n}}{\outputp{p^{lr}}{p}}}} \\
   	\meaningof{\mathsf{*} P}_{2nd} (  n, p )
   		& = & \binpar{\lift{x}{\meaningof{P}_{3rd}( n^{r}, p^{r} )}}
		             {\binpar{D(x)}{\binpar{\outputp{n^{r}}{n^{l}}}{\outputp{p^{r}}{p^{l}}}}} \\
   	\meaningof{\id{(}\nu \; x \id{)} P}_{2nd} (  n, p ) 
   		& = & 
 		\prefix{p}{x}{\binpar{\meaningof{P}_{2nd} ( n^{l}, p^{l} )}{\outputp{p}{n}}} \\
\end{eqnarray*}

and

\begin{eqnarray*}
	x^{l} & \triangleq & \quotep{\outputp{x}{x}} \\
	x^{r} & \triangleq & \quotep{\prefix{x}{x}{\pzero}} \\
	\meaningof{P}_{3rd}( n'', p'' ) 
		& \triangleq & 
			\prefix{n''}{n}{\prefix{p''}{p}{(\binpar{\meaningof{P}_{2nd}(  n, p )}
							        {(\binpar{D(x)}{\binpar{\outputp{n''}{n^{l}}}{\outputp{p''}{p^{l}}}})})}} \\
\end{eqnarray*}

\begin{remark}
	Note that all $\nu$-binding is now interpreted, as in Wischik's
	global $\pi$-calculus, as an input guard \cite{globalpi}.
\end{remark}
	
\begin{remark}
	It is also noteworthy that the translation is dependent on how
	the parallel compositions in a process are
	associated. Different associations will result in different
	bindings for $\nu$-ed names. This will not result in different
	behavior, however, as the bindings will be consistent
	throughout the translation of the process.
\end{remark}

\begin{theorem}[Correctness]	
	$P \wbbisim_{\pi} Q \iff \ldb P \rdb \wbbisim_{r(\texttt{FN}(P))} \ldb Q \rdb$.
\end{theorem}

\emph{Proof sketch}: An easy structural induction.

One key point in the proof is that there are contexts in the {\rhoc}
that will distinguish the translations. But, these are contexts that
can see the fresh names, $n$, and the communication channel, $p$, for
the `memory allocator'. These contexts do not correspond to any
observation that can be made in the {\pic} and so we exclude them in
the {\rhoc} side of our translation by our choice of ${\mathsf N}$
for the bisimulation. This is one of the technical motivations behind
our introduction of a less standard bisimulation.

\begin{example}
	In a similar vein consider, for an appropriately chosen $p$ and $n$ we have
	\begin{equation*}
		\meaningof{(\mathsf{new}\;v)(\mathsf{new}\;v) u!(v)} = \mathsf{for}(v \leftarrow p)(\mathsf{for}({v} \leftarrow {\quotep{p!(p)}})(u!(v)|\quotep{p!(p)})!(\quotep{n!(n)})) | p!(n)
	\end{equation*}
	and
	\begin{equation*}
		\meaningof{(\mathsf{new}\;v)u!(v)} = \mathsf{for}(v \leftarrow p)(u!(v) )|p!(n)
	\end{equation*}

	Both programs will ultimately result in an output of a single
	fresh name on the channel $u$. But, the former program will
	consume more resources. Two names will be allocated; two memory
	requests will be fulfilled. The {\rhoc} can see this, while the
	{\pic} cannot. In particular, the {\pic} requires that
	$(\mathsf{new}\;x)(\mathsf{new}\;x)P \equiv (\mathsf{newp} x)P$.

	Implementations of the {\pic}, however, having the property that
	$(\mathsf{new}\;x)P$ involves the allocation of memory for the
	structure representing the channel $x$ come to grips with the
	implications this requirement has regarding memory management. If
	memory is allocated upon encountering the $\nu$-scope, there are
	situations where the left-hand side of the equation above will
	fail while the right-hand will succeed. Remaining faithful to the
	equation above requires that such implementations are
	\textit{lazy} in their interpretation of $(\mathsf{new}\;x)P$, only
	allocating the memory for the fresh channel at the first moment
	when that channel is used.

	Having a detailed account of the structure of names elucidates
	this issue at the theoretical level and may make way to offer
	guidance to implementations.
\end{example}

\end{document}

